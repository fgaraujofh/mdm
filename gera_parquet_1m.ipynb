{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51141f25-3950-465f-84ec-7114bcbe6216",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "from graphframes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "692f6c25-16d4-412f-81a9-99cb44ee0025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados de carga\n",
    "csv_pj = 'dataset/empresas_estabelecimentos_1m.csv'\n",
    "csv_socios = 'dataset/socios_1m.csv'\n",
    "maior_cnpj = '04258527'\n",
    "menor_cnpj = '03230095'\n",
    "parquet_nodes = 'dataset/grapho/nodes_1m'\n",
    "parquet_edges = 'dataset/grapho/edges_1m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6394fb76-dbb9-4fd3-aed5-e693813e074c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/09 09:00:34 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .config(\"spark.driver.memory\", \"128g\") \\\n",
    "        .appName(\"gera_arvore1\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a11b7b67-5803-4188-a8b5-5543a62776c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema para Json Empresa\n",
    "json_schema_em = StructType([\n",
    "    StructField(\"porteEmpresa\", StringType(), True),\n",
    "    StructField(\"capitalSocial\", StringType(), True),\n",
    "    StructField(\"cpfResponsavel\", StringType(), True),\n",
    "    StructField(\"nomeEmpresarial\", StringType(), True),\n",
    "    StructField(\"naturezaJuridica\", StringType(), True),\n",
    "    StructField(\"qualificacaoResponsavel\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Schema para Json Estabelecimento\n",
    "json_schema_es = StructType([\n",
    "    StructField(\"uf\", StringType(), True),\n",
    "    StructField(\"cep\", StringType(), True),\n",
    "    StructField(\"ddd1\", StringType(), True),\n",
    "    StructField(\"ddd2\", StringType(), True),\n",
    "    StructField(\"pais\", StringType(), True),\n",
    "    StructField(\"email\", StringType(), True),\n",
    "    StructField(\"bairro\", StringType(), True),\n",
    "    StructField(\"numero\", StringType(), True),\n",
    "    StructField(\"municipio\", StringType(), True),\n",
    "    StructField(\"telefone1\", StringType(), True),\n",
    "    StructField(\"telefone2\", StringType(), True),\n",
    "    StructField(\"cnaeFiscal\", StringType(), True),\n",
    "    StructField(\"logradouro\", StringType(), True),\n",
    "    StructField(\"complemento\", StringType(), True),\n",
    "    StructField(\"dataCadastro\", StringType(), True),\n",
    "    StructField(\"nomeFantasia\", StringType(), True),\n",
    "    StructField(\"cidadeExterior\", StringType(), True),\n",
    "    StructField(\"tipoLogradouro\", StringType(), True),\n",
    "    StructField(\"cnaesSecundarias\", StringType(), True),\n",
    "    StructField(\"situacaoEspecial\", StringType(), True),\n",
    "    StructField(\"situacaoCadastral\", StringType(), True),\n",
    "    StructField(\"dataSituacaoEspecial\", StringType(), True),\n",
    "    StructField(\"dataSituacaoCadastral\", StringType(), True),\n",
    "    StructField(\"motivoSituacaoCadastral\", StringType(), True),\n",
    "    StructField(\"identificadorMatrizFilial\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Definindo o esquema para leitura do CSV\n",
    "schema = StructType([\n",
    "    StructField(\"nu_cnpj_raiz\", StringType(), True),\n",
    "    StructField(\"te_dados_em\", StringType(), True),\n",
    "    StructField(\"id_estabelecimento\", StringType(), True),\n",
    "    StructField(\"te_dados_es\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Lendo o CSV com o esquema definido\n",
    "pj = spark.read \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .option(\"multiline\", \"true\") \\\n",
    "    .option(\"escape\", \"\\\"\") \\\n",
    "    .csv(csv_pj, schema=schema, header=True)\n",
    "\n",
    "pj = pj.withColumn(\"te_dados_em\", from_json(col(\"te_dados_em\"), json_schema_em)) \\\n",
    "      .withColumn(\"te_dados_es\", from_json(col(\"te_dados_es\"), json_schema_es)) \\\n",
    "      .filter(substring(col(\"id_estabelecimento\"), 0, 4) == '0001') \\\n",
    "      .withColumnRenamed(\"nu_cnpj_raiz\", \"id\")\n",
    "\n",
    "pj = pj.orderBy(col(\"id\").asc()).dropDuplicates(['id'])\n",
    "\n",
    "# verificando unidade de chaves:\n",
    "# count_df = pj.groupBy('id').count()\n",
    "# repeated_cnpj = count_df.filter(col('count') > 1)\n",
    "# repeated_cnpj.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb38ae22-cecd-4f52-af56-b360ea80a75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema para Json Socios\n",
    "json_schema_sc = StructType([\n",
    "    StructField(\"pais\", StringType(), True),\n",
    "    StructField(\"entradaSociedade\", StringType(), True),\n",
    "    StructField(\"socioEstrangeiro\", StringType(), True),\n",
    "    StructField(\"qualificacaoSocio\", StringType(), True),\n",
    "    StructField(\"identificadorSocio\", StringType(), True),\n",
    "    StructField(\"cpfRepresentanteLegal\", StringType(), True),\n",
    "    StructField(\"qualificacaoRepresentanteLegal\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Definindo o esquema para leitura do CSV\n",
    "schema = StructType([\n",
    "    StructField(\"nu_cnpj_raiz\", StringType(), True),\n",
    "    StructField(\"id_socio\", StringType(), True),\n",
    "    StructField(\"te_dados_sc\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Lendo o CSV com o esquema definido\n",
    "socio = spark.read \\\n",
    "        .option(\"delimiter\", \",\") \\\n",
    "        .option(\"multiline\", \"true\") \\\n",
    "        .option(\"escape\", \"\\\"\") \\\n",
    "        .csv(csv_socios, schema=schema, header=True)\n",
    "\n",
    "# tratando o df socios\n",
    "# Tratamento 1: Expandir o JSON\n",
    "socio = socio.withColumn(\"te_dados_sc\", from_json(col(\"te_dados_sc\"), json_schema_sc))\n",
    "\n",
    "# converte cnpj para nu_cnpj_raiz\n",
    "socio = socio.withColumn(\"id_socio\", when(socio[\"te_dados_sc\"][\"identificadorSocio\"] == '1',\n",
    "                                    socio[\"id_socio\"].substr(1, 8))\n",
    "                                .otherwise(socio[\"id_socio\"]))\n",
    "# Remomeia fonte e destino\n",
    "socio = socio.withColumnRenamed(\"nu_cnpj_raiz\", \"src\").withColumnRenamed(\"id_socio\", \"dst\")\n",
    "# Ordena por src, dst e remove arestas dubplicadas\n",
    "socio = socio.orderBy(col(\"src\").asc(), col(\"dst\").asc()).dropDuplicates(['src', 'dst'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b02b073d-916b-435f-ac52-0e827bba7edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria df para vértices do tipo Pessoa Física:\n",
    "pf = socio.filter(col(\"te_dados_sc.identificadorSocio\") == '2').select(col(\"dst\").alias(\"id\")).distinct()\n",
    "\n",
    "# Cria df para vértices de PJs que não foram exportados, mas estão no dst dos sócios\n",
    "filtro = (col(\"te_dados_sc.identificadorSocio\") == '1') & ((col(\"dst\") > maior_cnpj) | (col(\"dst\") < menor_cnpj))\n",
    "pj_extra = socio.filter(filtro).select(col(\"dst\").alias(\"id\")).distinct()\n",
    "\n",
    "cols_pj = [col_name for col_name in pj.columns if col_name != 'id']\n",
    "for col_name in cols_pj:\n",
    "    pf = pf.withColumn(col_name, lit(None))\n",
    "    pj_extra = pj_extra.withColumn(col_name, lit(None))\n",
    "\n",
    "# cria tipo de pessoa nos vértices\n",
    "pj = pj.withColumn(\"id_tipoPessoa\", lit(1))\n",
    "pj_extra = pj_extra.withColumn(\"id_tipoPessoa\", lit(1))\n",
    "pf = pf.withColumn(\"id_tipoPessoa\", lit(2))\n",
    "\n",
    "# Cria tipo de relacionamento no socio\n",
    "socio = socio.withColumn(\"id_tipoRel\", lit(1))\n",
    "\n",
    "pj = pj.union(pj_extra)\n",
    "vertex = pj.union(pf).orderBy(\"id\")\n",
    "\n",
    "# verificando unidade de chaves:\n",
    "# count_df = vertex.groupBy('id').count()\n",
    "# repeated_vertex = count_df.filter(col('count') > 1)\n",
    "# repeated_vertex.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49d900d0-5945-461d-a54b-fe6515ffca3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# gera arquivo parquet de socio\n",
    "socio.write.mode('overwrite').parquet(parquet_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4b01432-b47a-4a72-bd62-a957835d631a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/09 09:01:04 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# gera arquivo parquet de pessoas\n",
    "pj.write.mode('overwrite').parquet(parquet_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6dd05793-99cf-4bd8-89b2-ac766ad44820",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
